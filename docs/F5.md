# F5 Search file chunks by concept

## 1 Why concept search?

Exact keywords can miss the passage you need.
F5 lets you issue a *semantic* (vector or hybrid) query that returns the most relevant **chunks** of text, even if the words differ.

```
index      : file_chunks         # created automatically
embedder   : e5-small            # chosen at start‑up (see §2.2)
```

---

## 2 How it works

### 2.1 Generate text once per file

1. A module of your choice outputs **raw text** for every file.
   For each file Home‑Index writes:

```
output/metadata/by-id/<file‑hash>/<text‑module>/
├── content.json   # full text or list of segments
└── chunks.json    # auto‑generated (see §2.3)
```

### 2.2 Chunk & embed automatically

Environment variables on **home-index** drive the behaviour:

| Variable           | Default  | Purpose                                                                |
| ------------------ | -------- | ---------------------------------------------------------------------- |
| `TOKENS_PER_CHUNK` | 256      | Target chunk length (token count before overlap added).                |
| `CHUNK_OVERLAP`    | 32       | Overlapping tokens between adjacent chunks (0 – *N*).                  |
| `EMBED_MODEL_NAME` | e5-small | Any model supported by `sentence-transformers`; changing it re‑embeds. |

Changing any of the above after a successful run triggers a **clean rebuild** of all `chunks.json` files while leaving `content.json` untouched.

### 2.3 Chunk document schema

Each entry in *any* `chunks.json` **must** expose:

```
id            string   unique chunk identifier
file_id       string   SHA‑256 of the source file
module        string   name of the module that supplied the text
text          string   the chunk’s text
index         int      0‑based position within the file
start_time    float    seconds (‑1 if N/A)
char_offset   int      byte position of first character
char_length   int      length in bytes
```

### 2.4 Querying by concept

POST to `/indexes/file_chunks/search` with *any* Meilisearch vector or hybrid syntax.
For best recall prefix:

* each **document** with `"passage: "` (applied automatically), and
* each **query**  with `"query: "` (do this in your client).

`sort`, `limit`, `offset`, and all Meilisearch filters work as expected.

---

## 3 Minimal `docker-compose.yml`

```yaml
services:
  home-index:
    image: ghcr.io/nashspence/home-index:latest
    environment:
      MODULES: |
        - name: text-module
      TOKENS_PER_CHUNK: 256
      CHUNK_OVERLAP: 32
      EMBED_MODEL_NAME: e5-small
      METADATA_DIRECTORY: /home-index/metadata
      REDIS_HOST: http://redis:6379
    volumes:
      - ./input:/files:ro
      - ./output:/home-index
    depends_on: [meilisearch, text-module, redis]

  meilisearch:
    image: getmeili/meilisearch:v1.15
    environment: [MEILI_NO_ANALYTICS=true]
    volumes:   [./output/meili:/meili_data]
    ports: ["7700:7700"]

  text-module:
    build: ./text_module                       # emits content.json for each file
    environment:
      METADATA_DIRECTORY: /home-index/metadata
      QUEUE_NAME: text-module
      REDIS_HOST: http://redis:6379
    volumes:
      - ./input:/files:ro
      - ./output:/home-index

  redis:
    image: redis:7
    command: redis-server --loglevel verbose
    ports: ["6379:6379"]
```

---

## 4 Acceptance criteria (platform‑agnostic)

| #      | Scenario & pre‑conditions                                                                                                   | Steps (user actions → expected result)                                                                                                                                                                                              |
| ------ | --------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **1**  | **Initial build – existing files become searchable**<br>Stack starts with at least one file and a module that outputs text. | 1 Start stack → For every file, `content.json` and `chunks.json` appear.<br>2 Issue a concept query phrased differently from the text → Response contains at least one chunk whose `file_id` matches the expected file hash.        |
| **2**  | **New file added while running**                                                                                            | 1 Copy a new file into `/files` → New `content.json` and `chunks.json` appear; concept query over new content returns its chunks.                                                                                                   |
| **3**  | **File contents change**                                                                                                    | 1 Replace an existing file’s bytes (hash changes).<br>2 Wait → A new metadata directory (new hash) and new chunks are created; old one remains.                                                                                     |
| **4**  | **Chunk document schema is complete**                                                                                       | 1 Open any produced `chunks.json` → Every chunk object includes exactly the fields listed in §2.3 with valid (non‑null) values.                                                                                                     |
| **5**  | **Search results can be sorted & paged**                                                                                    | 1 Send a search with `"sort":["index:asc"], "limit":3, "offset":2"` → Returned hits are in ascending `index` order, starting from logical chunk 3.                                                                                  |
| **6**  | **Chunk size / overlap change triggers rebuild**                                                                            | 1 Stop stack and change either `TOKENS_PER_CHUNK` or `CHUNK_OVERLAP`.<br>2 Restart → `output/chunk_settings.json` reflects new values and timestamps of all affected `chunks.json` files increase; chunk counts change accordingly. |
| **7**  | **Embed model change triggers re‑embedding only**                                                                           | 1 After a successful run, change `EMBED_MODEL_NAME` to another supported model and restart.<br>2 All `chunks.json` files are rewritten (new timestamps), yet all `content.json` files stay byte‑identical.                          |
| **8**  | **Warm restart – settings unchanged**                                                                                       | 1 Stop all containers after success.<br>2 Restart with *identical* environment variables → No `chunks.json` timestamps change; no unnecessary Meilisearch updates occur.                                                            |
| **9**  | **Deletion is reflected in the index**                                                                                      | 1 Delete a file from `/files` and restart stack (or trigger rescanning method).<br>2 Chunks linked to the removed file disappear from Meilisearch results and from `output/metadata`.                                               |
| **10** | **Hybrid search with filter returns correct subset**                                                                        | 1 Add a metadata filter (e.g., `"filter":"module = 'text-module'"`) to a hybrid search.<br>2 Results include only chunks whose `module` equals the filter value and still respect semantic ranking.                                 |

All scenarios must pass unchanged on Linux, macOS, and Windows (WSL).

---

**End of specification**
