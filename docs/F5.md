# F5. "I want to search file chunks by concept"

## Value

Concept search surfaces relevant passages even when you don't know the exact words.

---

## Usage

Modules emit chunk documents with text segments. To search them by concept,
configure Meilisearch with a local Hugging Face embedder:

1. **Run Meilisearch with built-in vector search**

   ```bash
   docker pull getmeili/meilisearch:v1.15
   docker run -it --rm \
     -p 7700:7700 \
     -e MEILI_ENV=development \
     -v $(pwd)/meili_data:/meili_data \
     getmeili/meilisearch:v1.15
   ```

2. **Create (or reuse) the chunk index**

   ```bash
   curl -X POST 'localhost:7700/indexes/file_chunks' \
        -H 'Content-Type: application/json' \
        --data '{"primaryKey":"id"}'
   ```

3. **Patch the local embedder**

   ```bash
   curl -X PATCH 'localhost:7700/indexes/file_chunks/settings/embedders' \
     -H 'Content-Type: application/json' \
     --data-binary '{
       "e5-small": {
         "source": "huggingFace",
         "model": "intfloat/e5-small-v2",
         "dimensions": 384,
         "documentTemplate": "passage: {{doc.text}}"
       }
     }'
   ```

4. **Index your content**

   ```bash
   curl -X POST 'localhost:7700/indexes/file_chunks/documents' \
     -H 'Content-Type: application/json' \
     --data-binary '[{"id":"1","file_id":"1","text":"Why positive psychology works"}]'
   ```

   As documents arrive, Meilisearch expands the template to add the
   `passage:` prefix, generates 384-dimensional vectors and stores them under
   `_vectors.e5-small`.

5. **Querying**

   Let Meilisearch embed the query for you:

   ```bash
   curl -X POST 'localhost:7700/indexes/file_chunks/search' \
     -H 'Content-Type: application/json' \
     --data-binary '{
       "q": "query: positive psychology books",
       "hybrid": { "semanticRatio": 1, "embedder": "e5-small" }
     }'
   ```

6. **Checklist & gotchas**

   | ✔︎                 | Must-do |
   | ------------------ | ------------------------------------------------------------ |
   | CPU only?          | Works, but indexing is slower. Use the GPU build for big datasets. |
   | Disk/ram           | Model ≈ 50 MB + index. Keep the `meili_data` volume for persistence. |
   | Prefixes           | **Every document** → `passage:`; **every query** → `query:`. Skipping them hurts recall. |
   | Monitoring         | Track long operations with `/tasks` or enable task webhooks for alerts. |
   | Tweaking relevancy | Adjust `semanticRatio` at query time—`0` = classic search, `1` = vector, anything in between is hybrid. |

Index your documents normally. Meilisearch expands the template and stores the
resulting vectors under `_vectors.e5-small`.

Search with a query prefixed by `query:` and reference the embedder by name:

```bash
curl -X POST 'http://localhost:7700/indexes/file_chunks/search' \
  -H 'Content-Type: application/json' \
  --data '{
    "q": "query: positive psychology",
    "hybrid": {"semanticRatio": 1, "embedder": "e5-small"}
  }'
```

The response contains matching chunks along with their parent file IDs.

---

## Minimal `docker-compose.yml`

```yaml
services:
  home-index:
    image: ghcr.io/nashspence/home-index:latest
    environment:
      - METADATA_DIRECTORY=/home-index/metadata
      - MODULES=http://chunk-module:9000
    volumes:
      - ./input:/files:ro
      - ./output:/home-index
    depends_on:
      - meilisearch
      - chunk-module
  meilisearch:
    image: getmeili/meilisearch:v1.15
    environment:
      - MEILI_NO_ANALYTICS=true
    volumes:
      - ./output/meili:/meili_data
    ports:
      - "7700:7700"
  chunk-module:
    build: ./chunk_module
    environment:
      - METADATA_DIRECTORY=/home-index/metadata
    volumes:
      - ./input:/files:ro
      - ./output:/home-index
```

---

## Input ↔ Output

| **Your single action** | **What you will literally see** |
| --- | --- |
| Run `docker compose up -d` with a module that emits chunk documents | A subfolder for the module appears under `./output/metadata/by-id/<file-hash>/` containing chunk JSON files. Vector searches on the `file_chunks` index return those chunks. |

---

## Acceptance

1. After indexing completes, a chunk JSON file exists under `./output/metadata/by-id/<file-hash>/chunk_module/`.
2. Searching the `file_chunks` index with the query vector returns the chunk document when filtered by `file_id`.
3. The chunk document includes `id`, `file_id`, `module`, `text`, and `_vector` fields.
