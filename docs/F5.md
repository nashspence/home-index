# F5. “I want to search file chunks by concept”

## Value

Concept search surfaces the passages you need even when you don’t know the exact words.

---

## Usage

Home-Index configures Meilisearch automatically:

```text
index  : file_chunks
embedder : e5-small        # declared at startup
```

A typical workflow is:

1. **Provide text** – Run a module that returns raw text (or segments) for every file.
   Home-Index stores that text in `content.json`, splits it into fixed-size chunks, and writes the chunks to `chunks.json`.

2. **Query by meaning** – Send a vector (or hybrid) search to `/indexes/file_chunks/search` and filter or sort the results as needed.
   *Tip – prefix every document with `passage:` and every query with `query:` for best recall.*

3. **Tweak as you grow** – Change `TOKENS_PER_CHUNK`, `CHUNK_OVERLAP`, or `EMBED_MODEL_NAME` to re-chunk or re-embed without touching the module.

---

## Acceptance

### Scenario 1 – First sync produces searchable chunks

| # | Home-Index **input**                                                                                             | Home-Index **output**                                                                                                                    |
| - | ---------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- |
| 1 | Start the stack with a module that returns content chunks for at least one file.                      | For every processed file a folder `output/metadata/by-id/<file-hash>/chunk-module/` appears containing `content.json` and `chunks.json`. |
| 2 | Run a concept query that expresses the same idea with different words. | The search response includes at least one chunk whose `file_id` equals the file’s hash.                                                  |

### Scenario 2 – Chunk documents expose required fields

| # | Home-Index **input**                           | Home-Index **output**                                                                                                          |
| - | ---------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------ |
| 1 | Open any `chunks.json` produced in Scenario 1. | Each chunk object contains **all** of: `id`, `file_id`, `module`, `text`, `index`, `start_time`, `char_offset`, `char_length`. |

### Scenario 3 – Results can be paged in document order

| # | Home-Index **input**                                              | Home-Index **output**                   |
| - | ----------------------------------------------------------------- | --------------------------------------- |
| 1 | Send a search with `"sort": ["index:asc"]` against `file_chunks`. | Hits return in ascending `index` order. |

### Scenario 4 – Changing chunk sizes or overlap rebuilds data

| # | Home-Index **input**                                                                                       | Home-Index **output**                                                                                                                                                 |
| - | ---------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1 | After Scenario 1, stop the stack and restart it with new values for `TOKENS_PER_CHUNK` or `CHUNK_OVERLAP`. | `output/chunk_settings.json` updates to the new values, and every affected `chunks.json` is regenerated (timestamp increases, chunk count reflects the new settings). |

### Scenario 5 – Switching the embed model triggers re-embedding

| # | Home-Index **input**                                                     | Home-Index **output**                                                                                                                                                           |
| - | ------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1 | After Scenario 1, restart the stack with a different `EMBED_MODEL_NAME`. | `output/chunk_settings.json` records the new model name and all `chunks.json` files are rewritten (timestamp increases) while the original `content.json` files stay unchanged. |

---

## Minimal `docker-compose.yml`

```yaml
services:
  home-index:
    image: ghcr.io/nashspence/home-index:latest
    environment:
      MODULES: |
        - name: chunk-module
      METADATA_DIRECTORY: /home-index/metadata
      REDIS_HOST: http://redis:6379
    volumes:
      - ./input:/files:ro
      - ./output:/home-index
    depends_on:
      - meilisearch
      - chunk-module
      - redis

  meilisearch:
    image: getmeili/meilisearch:v1.15
    environment:
      - MEILI_NO_ANALYTICS=true
    volumes:
      - ./output/meili:/meili_data
    ports:
      - "7700:7700"

  chunk-module:
    build: ./chunk_module
    environment:
      - METADATA_DIRECTORY=/home-index/metadata
      - QUEUE_NAME=chunk-module
      - REDIS_HOST=http://redis:6379
    volumes:
      - ./input:/files:ro
      - ./output:/home-index

  redis:
    image: redis:7
    command: redis-server --loglevel verbose
    ports:
      - "6379:6379"
```
