# F2. "I want to search for unique files by metadata"

## Value

Searching the index lets you quickly surface individual files even when duplicates exist.

---

## Usage

When the container indexes your files, each document is stored under `metadata/by-id/<file-id>/document.json` and every path gets a symlink in `metadata/by-path/`. The `<file-id>` value is an xxhash64 digest of the file contents. Duplicate files share one document whose `paths` map lists all locations and the `copies` field counts them. This field is filterable so you can query unique files directly or search for duplicates.
The search index exposes `copies` as a filterable attribute.

```bash
curl -X POST 'http://localhost:7700/indexes/files/search' \
  -H 'Content-Type: application/json' \
  --data '{"q": "", "filter": "copies = 1"}'
```

The result includes each unique file and shows its metadata.

Example response snippet:

```json
{
  "id": "<file-hash>",
  "paths": {"c.txt": 1700000000},
  "mtime": 1700000000,
  "size": 7,
  "type": "text/plain",
  "copies": 1
}
```

You can also search for duplicate files by filtering on the number of copies:

```bash
curl -X POST 'http://localhost:7700/indexes/files/search' \
  -H 'Content-Type: application/json' \
  --data '{"q": "", "filter": "copies = 2"}'
```

This query returns a single document listing every path to the duplicates with
`"copies": 2`.

---

## Minimal `docker-compose.yml`

```yaml
services:
  home-index:
    image: ghcr.io/nashspence/home-index:latest
    environment:
      - METADATA_DIRECTORY=/home-index/metadata
    volumes:
      - ./input:/files:ro
      - ./output:/home-index
    depends_on:
      - meilisearch
  meilisearch:
    image: getmeili/meilisearch:latest
    environment:
      - MEILI_NO_ANALYTICS=true
    volumes:
      - ./output/meili:/meili_data
    ports:
      - "7700:7700"
```

The container performs an initial sync on startup and then runs daily at 2 AM by default.

---

## User Testing

```bash
mkdir -p input output
printf 'duplicate' > input/a.txt
cp input/a.txt input/b.txt
echo 'unique' > input/c.txt
IMAGE=ghcr.io/nashspence/home-index:latest docker compose up -d
```

After the first sync completes, inspect `output/metadata/by-id/` to see one folder for `a.txt` and `b.txt` and another for `c.txt`. Under `output/metadata/by-path/` each file path appears as a symlink. The duplicates share a single document whose `copies` value is `2`.

Query Meilisearch to fetch the unique file by its metadata:

```bash
curl -X POST 'http://localhost:7700/indexes/files/search' \
  -H 'Content-Type: application/json' \
  --data '{"q": "", "filter": "paths IN [\"c.txt\"]"}'
```

The returned document lists only `c.txt` with `"copies": 1`.

You can verify duplicates with another search:

```bash
curl -X POST 'http://localhost:7700/indexes/files/search' \
  -H 'Content-Type: application/json' \
  --data '{"q": "", "filter": "copies = 2"}'
```

This shows the document for `a.txt` and `b.txt` with `"copies": 2`.

---

## Input ↔ Output

| **Your single action** | **What you will literally see** |
| --- | --- |
| Run `docker compose up -d` with the files above | Metadata appears under `./output/metadata/by-id/` and symlinks under `./output/metadata/by-path/`. Searching with the queries above returns the documents showing `"copies": 1` for `c.txt` and `"copies": 2` for `a.txt`/`b.txt`. |

---

## Acceptance

1. With the three files shown above, exactly two directories appear under `./output/metadata/by-id/` and each path under `./output/metadata/by-path/` resolves to one of those directories.
2. `document.json` for `a.txt`/`b.txt` records `"copies": 2`.
3. Querying the search index for `copies = 2` returns that single document.
4. Querying the search index for `copies = 1` returns the document for `c.txt`.
5. Querying by file `id`, by `paths IN ["c.txt"]`, by that document's `mtime`, by MIME `type` and by `copies = 1` each return the same single document.
